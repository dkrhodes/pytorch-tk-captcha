{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7edfebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class ImagePairDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.image_pairs = os.listdir(data_dir)[:64]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_pairs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        pair_dir = os.path.join(self.data_dir, self.image_pairs[index])\n",
    "        angle_file = os.path.join(pair_dir, 'angle.txt')\n",
    "        with open(angle_file, 'r') as f:\n",
    "            angle = float(f.read().strip())\n",
    "        \n",
    "        bg_path = os.path.join(pair_dir, 'bg.jpg')\n",
    "        bg_image = Image.open(bg_path).convert(\"L\")\n",
    "        cut_path = os.path.join(pair_dir, 'cut.jpg')\n",
    "        cut_image = Image.open(cut_path).convert(\"L\")\n",
    "        \n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        \n",
    "        bg_tensor = transform(bg_image)\n",
    "        cut_tensor = transform(cut_image)\n",
    "        \n",
    "        return bg_tensor, cut_tensor, torch.tensor(angle, dtype=torch.float)\n",
    "\n",
    "class ImagePairModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImagePairModel, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128 * 7396, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "    def forward(self, bg, cut):\n",
    "        x1 = self.cnn(bg)\n",
    "        x2 = self.cnn(cut)\n",
    "        x = torch.add(x1, x2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for bg, cut, angle in train_loader:\n",
    "        bg, cut, angle = bg.to(device), cut.to(device), angle.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(bg, cut)\n",
    "        loss = criterion(outputs.squeeze(), angle)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "    print('Train Loss: {:.6f}'.format(train_loss))\n",
    "    \n",
    "def test(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for bg, cut, angle in test_loader:\n",
    "            bg, cut, angle = bg.to(device), cut.to(device), angle.to(device)\n",
    "            outputs = model(bg, cut)\n",
    "            loss = criterion(outputs.squeeze(), angle)\n",
    "            test_loss += loss.item()\n",
    "    test_loss /= len(test_loader)\n",
    "    print('Test Loss: {:.6f}'.format(test_loss))\n",
    "    \n",
    "def main():\n",
    "    # Hyperparameters\n",
    "    batch_size = 32\n",
    "    learning_rate = 0.001\n",
    "    num_epochs = 10\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Datasets and data loaders\n",
    "    train_dataset = ImagePairDataset('/tmp/train')\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataset = ImagePairDataset('/tmp/test')\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Model, loss function, and optimizer\n",
    "    model = ImagePairModel().to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        train(model, train_loader, criterion, optimizer, device)\n",
    "        test(model, test_loader, criterion, device)\n",
    "    \n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), 'model.pth')\n",
    "    \n",
    "# print(ImagePairModel())\n",
    "main()\n",
    "\n",
    "# train_dataset = ImagePairDataset('/tmp/train')\n",
    "# bg, cut, angle = train_dataset[0]\n",
    "# m = ImagePairModel().forward(bg, cut)\n",
    "# print(m.shape)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "# for bg, cut, angle in train_loader:\n",
    "#     m = ImagePairModel().forward(bg, cut)\n",
    "#     print(\"m.shape\", m.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cab32f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35e8503",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd385fe162c5ca0c84973b7dd5c518456272446b2b64e67c2a69f949ca7a1754"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
